{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/srl-oahu-1/srl-hawaii-1/ariannab/anaconda3/envs/torch_optuna/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys \n",
    "import pandas as pd\n",
    "import yaml\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.optim.lr_scheduler import CyclicLR, ReduceLROnPlateau\n",
    "import lightning as pl\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import torchvision.models as models\n",
    "\n",
    "# this needs to be installed from https://github.com/jacobgil/confidenceinterval\n",
    "import confidenceinterval as ci\n",
    "\n",
    "IM_SIZE = 224\n",
    "EPOCHS = 1000\n",
    "NUM_WORKERS = 60 \n",
    "\n",
    "torch.set_num_threads(NUM_WORKERS*2) \n",
    "torch.manual_seed(1120)\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from modules import define_df, retrieve_cancer_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in the predictions\n",
    "test_input_file = \"sample_data/predictions.pkl\"\n",
    "with open(test_input_file, 'rb') as f:\n",
    "    test_predictions = pickle.load(f)\n",
    "\n",
    "test_densenet = define_df(['densenet_preds'], test_predictions)\n",
    "test_densenet_pat = define_df(['densenet_preds'], test_predictions, patient_level=True)\n",
    "test_densenet_pat['prediction_single'] = np.argmax(test_densenet_pat[['A_densenet_preds', 'B_densenet_preds', 'C_densenet_preds', 'D_densenet_preds']].to_numpy(), axis=1)\n",
    "\n",
    "# original radiologist assignments \n",
    "testing_raw = pd.read_csv(\"sample_data/sample_data.csv\")\n",
    "\n",
    "test_densenet_pat['cancer'] = test_densenet_pat['ANALYSIS_ID'].apply(lambda x: retrieve_cancer_status(x, testing_raw))\n",
    "test_densenet['cancer'] = test_densenet['ANALYSIS_ID'].apply(lambda x: retrieve_cancer_status(x, testing_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_samples = {'ANALYSIS_ID' : [], 'sample' : [],  'clinical_density' : [], 'BUS_density' : [], 'cancer' : [], 'age' : []}\n",
    "\n",
    "for x in test_densenet_pat['ANALYSIS_ID'].tolist():\n",
    "    new_samples['ANALYSIS_ID'].extend([x] * 100)\n",
    "    new_samples['sample'].extend(list(range(100)))\n",
    "    new_samples['cancer'].extend(test_densenet_pat[test_densenet_pat['ANALYSIS_ID'] == x]['cancer'].tolist() * 100)\n",
    "    new_samples['age'].extend(test_densenet_pat[test_densenet_pat['ANALYSIS_ID'] == x]['age_us'].tolist() * 100)\n",
    "    new_samples['clinical_density'].extend((test_densenet_pat[test_densenet_pat['ANALYSIS_ID'] == x]['labels'] - 1).tolist()* 100)\n",
    "\n",
    "    bus_probs = np.round(test_densenet_pat[test_densenet_pat['ANALYSIS_ID'] == x][['A_densenet_preds', 'B_densenet_preds', 'C_densenet_preds', 'D_densenet_preds']].to_numpy()[0], 3)\n",
    "    \n",
    "    if(sum(bus_probs) != 1):\n",
    "        bus_probs[1] = bus_probs[1] + ( 1 - sum(bus_probs))\n",
    "\n",
    "    new_samples['BUS_density'].extend(np.random.choice(4, size=100, p=bus_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our new sampled dataframe, then deduplicating for construction of odds ratios\n",
    "sampled_df = pd.DataFrame.from_dict(new_samples)\n",
    "sampled_df_dedup = sampled_df.sample(frac=1.0).drop_duplicates(subset='ANALYSIS_ID', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Cancer from predicted BUS BI-RADS density \n",
    "Because we're using the small sample dataset, we're not doing CV here. We did it with our full dataset in the paper. This is purely for illustrative purposes. Additionally, in the paper we construct odds ratios from `one_hot_encoded_df_dedup`. Due to the small size of the sample dataset, we are contructing from `one_hot_encoded_df`. **Both things must be amended if you want valid results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.28568169 -1.66198019 -1.61066036 29.24126416]]\n",
      "[-25.43176429]\n",
      "[0 1]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoded_df = pd.get_dummies(sampled_df, columns=['BUS_density'], prefix='BUS_density')\n",
    "# B is our reference category\n",
    "X = one_hot_encoded_df[['age', 'BUS_density_0', 'BUS_density_2', 'BUS_density_3']].values\n",
    "y = one_hot_encoded_df['cancer']\n",
    "\n",
    "one_hot_encoded_df_dedup = pd.get_dummies(sampled_df_dedup, columns=['BUS_density'], prefix='BUS_density')\n",
    "\n",
    "outer_cv = KFold(n_splits=3, shuffle=True, random_state=1120)\n",
    "\n",
    "ct = ColumnTransformer([ (\"passthrough\", \"passthrough\", [1, 2, 3]), ('scaler', StandardScaler(), [0])])\n",
    "pipe = Pipeline([('scaler', ct), ('model', LogisticRegression(random_state=1120, max_iter=10000, penalty=None, fit_intercept=True))])\n",
    "pipe.fit(X=X, y=y)\n",
    "nested_score = cross_val_score(pipe, X=X, y=y, cv=outer_cv, scoring='roc_auc_ovr')\n",
    "preds = cross_val_predict(pipe, X=X, y=y, cv=outer_cv, method='predict_proba')\n",
    "\n",
    "print(pipe['model'].coef_)\n",
    "print(pipe['model'].intercept_)\n",
    "print(pipe['model'].classes_)\n",
    "print(nested_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1159025/3758522736.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  SE = np.sqrt(np.linalg.inv(np.dot(np.dot(np.transpose(X), W), X)))\n"
     ]
    }
   ],
   "source": [
    "preds_dedup = pipe.predict_proba(X=one_hot_encoded_df[['age', 'BUS_density_0', 'BUS_density_2', 'BUS_density_3']])\n",
    "betas = np.insert(pipe['model'].coef_[0], 0, pipe['model'].intercept_).reshape((5, 1))\n",
    "X = np.hstack([np.ones((400, 1)), ct.fit_transform(one_hot_encoded_df[['age', 'BUS_density_0', 'BUS_density_2', 'BUS_density_3']])])\n",
    "W = np.diagflat(np.exp(np.dot(X, betas)) / ((1 + np.exp(np.dot(X, betas)))**2))\n",
    "# define standard errors \n",
    "SE = np.sqrt(np.linalg.inv(np.dot(np.dot(np.transpose(X), W), X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.62\n",
      "0.0\n",
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1159025/4157720483.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  print(np.exp(age_coef + 1.96*(SE[1, 1])).round(2))\n"
     ]
    }
   ],
   "source": [
    "# odds ratios for one SD increase in age \n",
    "# overflow is expected in the sample dataset\n",
    "age_coef = pipe['model'].coef_[0][0]\n",
    "print(np.exp(age_coef).round(2))\n",
    "print(np.exp(age_coef - 1.96*(SE[1, 1])).round(2))\n",
    "print(np.exp(age_coef + 1.96*(SE[1, 1])).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19\n",
      "0.0\n",
      "2.240449274008741e+144\n",
      "\n",
      "\n",
      "0.2\n",
      "0.0\n",
      "inf\n",
      "\n",
      "\n",
      "5004027270786.82\n",
      "0.0\n",
      "4.220613872876127e+163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1159025/3218370448.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  print(np.exp(C_coef + 1.96*(SE[3, 3])).round(2))\n"
     ]
    }
   ],
   "source": [
    "# overflow is expected with sample dataset \n",
    "A_coef = pipe['model'].coef_[0][1]\n",
    "print(np.exp(A_coef).round(2))\n",
    "print(np.exp(A_coef - 1.96*(SE[2, 2])).round(2))\n",
    "print(np.exp(A_coef + 1.96*(SE[2, 2])).round(2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# overflow is expected with sample dataset \n",
    "C_coef = pipe['model'].coef_[0][2]\n",
    "print(np.exp(C_coef).round(2))\n",
    "print(np.exp(C_coef - 1.96*(SE[3, 3])).round(2))\n",
    "print(np.exp(C_coef + 1.96*(SE[3, 3])).round(2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# overflow is expected with sample dataset \n",
    "D_coef = pipe['model'].coef_[0][3]\n",
    "print(np.exp(D_coef).round(2))\n",
    "print(np.exp(D_coef - 1.96*(SE[4, 4])).round(2))\n",
    "print(np.exp(D_coef + 1.96*(SE[4, 4])).round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_optuna",
   "language": "python",
   "name": "torch_optuna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
